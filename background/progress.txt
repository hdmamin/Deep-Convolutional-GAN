I started by building a Deep Convolutional GAN (DCGAN). The generator consists of five deconvolutional blocks which gradually upsample the height and width of the input (random noise) into an image. The discriminator consists of five convolutional blocks which gradually downsample the image height and width as it moves through the network. I added options for a few variations, so the user can select batch norm or instance norm or adjust the activation functions (this was mostly based on Jeremy Howard's experiments with ReLU variants). It is also possible to make tweaks to the training process, such as choosing to only train the discriminator every other mini batch since it sometimes overpowers the generator. While the results are not great for the sketch or photo datasets, I did validate that the DCGAN works by testing it on the CelebA dataset, where it works better. My guess is this could be related to the fact that the photo dataset only has 100 samples per class, and the classes are quite different from each other which the basic DCGAN methodology does not account for. I've been trying the model on a number of different datasets and experimenting with some of the variants mentioned above.

After the DCGAN, I built a simplified cycleGAN but am still in the process of checking if my code is running correctly. Initial attempts to train resulted in the discriminator completely overpowering the generator. I am also curious to see if transfer learning might be useful in GANs, and built a pre-trained discriminator but have not tested it yet. This is an individual project so I handled all responsibilities from finding datasets to building models and running experiments.

https://github.com/hdmamin/GAN-architectures

