{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:47:37.748549Z",
     "start_time": "2019-06-08T23:47:37.639239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:47:38.306504Z",
     "start_time": "2019-06-08T23:47:38.244461Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from htools import hdir\n",
    "from config import *\n",
    "from models import BaseModel, conv_block\n",
    "import models\n",
    "from utils import render_samples, show_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:47:48.968222Z",
     "start_time": "2019-06-08T23:47:48.903165Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEMPORARY, IMPORTED FROM CONFIG - JUST FOR EASY REFERENCE\n",
    "\n",
    "bs = 64                # Batch size (paper uses 128).\n",
    "img_size = 64          # Size of input (here it's 64 x 64).\n",
    "workers = 2            # Number of workers for data loader.\n",
    "input_c = 100          # Depth of input noise (1 x 1 x noise_dim). AKA nz.\n",
    "ngf = 64           # Filters in last layer before reduced to 3 (aka ngf.)\n",
    "ndf = 64             # Filters in first conv layer in D (aka ndf.)\n",
    "lr = 2e-4              # Recommended learning rate of .0002.\n",
    "beta1 = .5             # Recommended parameter for Adam.\n",
    "nc = 3                 # Number of channels of input image.\n",
    "ngpu = 1               # Number of GPUs to use.\n",
    "sample_dir = 'samples' # Directory to store sample images from G. \n",
    "weight_dir = 'weights' # Directory to store model weights.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and ngpu > 0 \n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:36:17.993809Z",
     "start_time": "2019-06-09T00:36:17.944473Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in):\n",
    "        super().__init__()\n",
    "        self.conv = conv_block(False, c_in, c_in, f=3, stride=1, pad=1, \n",
    "                               bias=False, bn=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:46:36.722901Z",
     "start_time": "2019-06-09T00:46:36.662181Z"
    }
   },
   "outputs": [],
   "source": [
    "class CycleGenerator(BaseModel):\n",
    "    \n",
    "    def __init__(self, img_c, ngf):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ENCODER\n",
    "        # 3 x 64 x 64 -> 64 x 32 x 32\n",
    "        deconv1 = conv_block(False, img_c, ngf, f=4, stride=2, pad=1)\n",
    "        # 64 x 32 x 32 -> 128 x 16 x 16\n",
    "        deconv2 = conv_block(False, ngf, ngf*2, 4, 2, 1)\n",
    "        self.encoder = nn.Sequential(deconv1, deconv2)\n",
    "\n",
    "        # TRANSFORMER\n",
    "        # 128 x 16 x 16 -> 128 x 16 x 16\n",
    "        res1 = ResBlock(ngf*2)\n",
    "        # 128 x 16 x 16 -> 128 x 16 x 16\n",
    "        res2 = ResBlock(ngf*2)\n",
    "        self.transformer = nn.Sequential(res1, res2)\n",
    "        \n",
    "        # DECODER\n",
    "        deconv1 = conv_block(True, ngf*2, ngf, )\n",
    "        \n",
    "        self.groups = nn.ModuleList([self.encoder, self.transformer])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for group in self.groups:\n",
    "            x = F.relu(group(x), inplace=True)\n",
    "#         x = F.relu(self.deconv1(x), inplace=True)\n",
    "#         x = F.relu(self.deconv2(x), inplace=True)\n",
    "#         x = F.relu(self.res1(x), inplace=True)\n",
    "#         x = F.relu(self.res1(x), inplace=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:46:37.598790Z",
     "start_time": "2019-06-09T00:46:37.547527Z"
    }
   },
   "outputs": [],
   "source": [
    "class CycleDiscriminator(BaseModel):\n",
    "    \n",
    "    def __init__(self, img_c=3, ndf=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_block(False, img_c, ndf, f=4, stride=2, pad=1)\n",
    "        \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:46:37.824101Z",
     "start_time": "2019-06-09T00:46:37.758340Z"
    }
   },
   "outputs": [],
   "source": [
    "G = CycleGenerator(img_c, ngf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:46:38.233399Z",
     "start_time": "2019-06-09T00:46:38.118593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 16, 16])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:41:52.336065Z",
     "start_time": "2019-06-09T00:41:52.273043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CycleGenerator(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (groups): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:42:00.028030Z",
     "start_time": "2019-06-09T00:41:59.959366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 64, 4, 4]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64, 128, 4, 4]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 3, 3]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 3, 3]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:36:20.577914Z",
     "start_time": "2019-06-09T00:36:20.516532Z"
    }
   },
   "outputs": [],
   "source": [
    "res = ResBlock(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T00:36:20.742166Z",
     "start_time": "2019-06-09T00:36:20.673091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 64, 64])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 64, 64)\n",
    "res(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
