{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:47:37.748549Z",
     "start_time": "2019-06-08T23:47:37.639239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T01:33:26.255755Z",
     "start_time": "2019-06-09T01:33:26.190579Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from htools import hdir\n",
    "from config import *\n",
    "from models import BaseModel, conv_block, Discriminator\n",
    "from utils import render_samples, show_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:47:48.968222Z",
     "start_time": "2019-06-08T23:47:48.903165Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEMPORARY, IMPORTED FROM CONFIG - JUST FOR EASY REFERENCE\n",
    "\n",
    "bs = 64                # Batch size (paper uses 128).\n",
    "img_size = 64          # Size of input (here it's 64 x 64).\n",
    "workers = 2            # Number of workers for data loader.\n",
    "input_c = 100          # Depth of input noise (1 x 1 x noise_dim). AKA nz.\n",
    "ngf = 64               # Filters in first G layer.\n",
    "ndf = 64               # Filters in first D layer.\n",
    "lr = 2e-4              # Recommended learning rate of .0002.\n",
    "beta1 = .5             # Recommended parameter for Adam.\n",
    "nc = 3                 # Number of channels of input image.\n",
    "ngpu = 1               # Number of GPUs to use.\n",
    "sample_dir = 'samples' # Directory to store sample images from G. \n",
    "weight_dir = 'weights' # Directory to store model weights.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and ngpu > 0 \n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:05:35.051699Z",
     "start_time": "2019-06-09T06:05:34.930071Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Residual block to be used in CycleGenerator. Note that the relu or \n",
    "    leaky must still be applied on the output.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, c_in, num_layers=2, leak=.02):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----------\n",
    "        c_in: int\n",
    "            # of input channels.\n",
    "        num_layers: int\n",
    "            Number of conv blocks inside the skip connection (default 2). \n",
    "            ResNet paper notes that skipping a single layer did not show\n",
    "            noticeable improvements.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.leak = leak\n",
    "        self.layers = nn.ModuleList([conv_block(False, c_in, c_in, 3, 1, 1) \n",
    "                                     for i in range(num_layers)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_out = x\n",
    "        for layer in self.layers:\n",
    "            x_out = F.leaky_relu(layer(x_out), self.leak)\n",
    "        return x + x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:06:51.328997Z",
     "start_time": "2019-06-09T06:06:51.237472Z"
    }
   },
   "outputs": [],
   "source": [
    "class CycleGenerator(BaseModel):\n",
    "    \"\"\"CycleGAN Generator.\"\"\"\n",
    "\n",
    "    def __init__(self, img_c=3, ngf=64, leak=.02):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----------\n",
    "        img_c: int\n",
    "            # of channels of input image.\n",
    "        ngf: int\n",
    "            # of channels in first convolutional layer.\n",
    "        leak: float\n",
    "            Slope of leaky relu where x < 0. Leak of 0 is regular relu.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.leak = leak\n",
    "        self.activation = nn.LeakyReLU(self.leak)\n",
    "\n",
    "        # ENCODER\n",
    "        # 3 x 64 x 64 -> 64 x 32 x 32\n",
    "        deconv1 = conv_block(False, img_c, ngf, f=4, stride=2, pad=1)\n",
    "        # 64 x 32 x 32 -> 128 x 16 x 16\n",
    "        deconv2 = conv_block(False, ngf, ngf*2, 4, 2, 1)\n",
    "        self.encoder = nn.Sequential(deconv1, \n",
    "                                     self.activation,\n",
    "                                     deconv2,\n",
    "                                     self.activation)\n",
    "\n",
    "        # TRANSFORMER\n",
    "        # 128 x 16 x 16 -> 128 x 16 x 16\n",
    "        res1 = ResBlock(ngf*2, num_layers=2, leak=self.leak)\n",
    "        # 128 x 16 x 16 -> 128 x 16 x 16\n",
    "        res2 = ResBlock(ngf*2, 2, self.leak)\n",
    "        self.transformer = nn.Sequential(res1,\n",
    "                                         self.activation,\n",
    "                                         res2,\n",
    "                                         self.activation)\n",
    "\n",
    "        # DECODER\n",
    "        # 128 x 16 x 16 -> 64 x 32 x 32\n",
    "        deconv1 = conv_block(True, ngf*2, ngf, f=4, stride=2, pad=1)\n",
    "        # 64 x 32 x 32 -> 3 x 64 x 64\n",
    "        deconv2 = conv_block(True, ngf, img_c, 4, 2, 1)\n",
    "        self.decoder = nn.Sequential(deconv1, \n",
    "                                     self.activation,\n",
    "                                     deconv2,\n",
    "                                     nn.Tanh())\n",
    "\n",
    "        # Module list of Sequential objects is helpful if we want to use \n",
    "        # different learning rates per group.\n",
    "        self.groups = nn.ModuleList([self.encoder,\n",
    "                                     self.transformer,\n",
    "                                     self.decoder])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for group in self.groups:\n",
    "            x = group(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:07:02.515098Z",
     "start_time": "2019-06-09T06:07:02.460629Z"
    }
   },
   "outputs": [],
   "source": [
    "# class CycleDiscriminator(BaseModel):\n",
    "    \n",
    "#     def __init__(self, img_c=3, ndf=64):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = conv_block(False, img_c, ndf, f=4, stride=2, pad=1)\n",
    "        \n",
    "#     def forward(self):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:07:02.761191Z",
     "start_time": "2019-06-09T06:07:02.682789Z"
    }
   },
   "outputs": [],
   "source": [
    "G = CycleGenerator(img_c, ngf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:07:03.023171Z",
     "start_time": "2019-06-09T06:07:02.908161Z"
    }
   },
   "outputs": [],
   "source": [
    "D = Discriminator(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:07:03.504905Z",
     "start_time": "2019-06-09T06:07:03.453785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.dims())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T06:07:58.869519Z",
     "start_time": "2019-06-09T06:07:58.800539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5343, -0.1951,  0.9742, -0.7906],\n",
       "          [ 0.3825, -0.0667,  0.6833, -0.9533],\n",
       "          [-0.5036, -0.9747,  0.4012,  0.8723],\n",
       "          [ 0.5653, -0.7044,  0.3609, -0.8299]],\n",
       "\n",
       "         [[ 0.0013, -0.9774, -0.5825,  0.4348],\n",
       "          [-0.4315,  0.0135,  0.9550, -0.1441],\n",
       "          [-0.4449, -0.7311, -0.6828, -0.1035],\n",
       "          [ 0.2147,  0.6039,  0.8773, -0.7132]],\n",
       "\n",
       "         [[ 0.6585, -0.5894,  0.6888,  0.2868],\n",
       "          [ 0.2329,  0.6130, -0.5606, -0.5357],\n",
       "          [-0.0258, -0.2218,  0.2809, -0.6998],\n",
       "          [-0.4595,  0.1366,  0.2749, -0.7526]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4473,  0.0556,  0.9664,  0.3324],\n",
       "          [ 0.3801, -0.2523, -0.7848,  0.4776],\n",
       "          [-0.6737,  0.9194, -0.7567,  0.5156],\n",
       "          [-0.4637, -0.6024,  0.4821, -0.7558]],\n",
       "\n",
       "         [[-0.8447, -0.8026,  0.5185,  0.1444],\n",
       "          [-0.5484,  0.8674,  0.9145,  0.5140],\n",
       "          [-0.4182, -0.8895,  0.9462, -0.6652],\n",
       "          [ 0.6073,  0.8936,  0.0090, -0.3644]],\n",
       "\n",
       "         [[ 0.8318, -0.8134,  0.8572, -0.0379],\n",
       "          [-0.9754, -0.8580,  0.0920, -0.0242],\n",
       "          [ 0.5606, -0.6888,  0.9590,  0.6232],\n",
       "          [-0.9900,  0.5688,  0.9581,  0.5701]]]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
