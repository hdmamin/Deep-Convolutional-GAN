{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T04:51:16.885710Z",
     "start_time": "2019-07-08T04:51:15.480160Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-67dde4e73f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJRelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcat_dl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_real_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/msan631/sketch2pix/torch_datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m#                                                           [.3, .3, .3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                                     ])\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mcat_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquickdraw_tfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mcat_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/fastai-env/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m    207\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           target_transform=target_transform)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/fastai-env/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/fastai-env/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Faster and available in Python 3.5 and above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from models import Generator, JRelu\n",
    "from torch_datasets import cat_dl\n",
    "from utils import show_samples, save_real_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T00:25:20.358363Z",
     "start_time": "2019-07-08T00:25:20.354934Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_dir = 'cat_samples5'\n",
    "output_dir = 'cat_samples_misc'\n",
    "epochs = [5, 6, 7, 8, 10, 12, 13, 14, 15, 31, 41, 44]\n",
    "fnames = [os.path.join(weight_dir, f'{e}.pth') for e in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T00:54:51.864856Z",
     "start_time": "2019-07-08T00:54:51.861245Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_generator(weight_path, activation, norm='bn'):\n",
    "    \"\"\"Load weights and return a DC Generator. Model remains in train mode\n",
    "    even at test time.\n",
    "    \"\"\"\n",
    "    G = Generator(act=activation, norm=norm)\n",
    "    states = torch.load(weight_path)\n",
    "    G.load_state_dict(states['g'])\n",
    "    G.train()\n",
    "    print(f'Weights loaded from {weight_path}.')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:27:40.488975Z",
     "start_time": "2019-07-08T01:27:40.483206Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_dc_samples(model, output_dir, fname, samples=64, noise=None,\n",
    "                        threshold=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----------\n",
    "    model: nn.Module\n",
    "        Generator\n",
    "    output_dir: str\n",
    "        Location to save generated samples.\n",
    "    fname: str\n",
    "        Name of output image file.\n",
    "    samples: int\n",
    "        Number of samples to generate.\n",
    "    noise: torch.tensor or None\n",
    "        If None, new random noise will be generated. When generating samples \n",
    "        for many different sets of weights, this means we can choose to use \n",
    "        the same noise or different noise for each sample.\n",
    "    threshold: float or None\n",
    "        If not None, use for post-processing to filter what values should be\n",
    "        counted as black.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    path = os.path.join(output_dir, fname)\n",
    "    if noise is None:\n",
    "        noise = torch.randn(samples, 100, 1, 1)\n",
    "    with torch.no_grad():\n",
    "        fake = model(noise).detach()\n",
    "    if threshold:\n",
    "        fake = (fake.mean(0) < thresh).astype(float)\n",
    "    vutils.save_image(fake, path, normalize=True, \n",
    "                      nrow=int(np.sqrt(samples)))\n",
    "    print(f'Output image saved to {path}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:28:09.823441Z",
     "start_time": "2019-07-08T01:28:09.819143Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_model_samples(weight_paths, output_dir, act, norm='bn', \n",
    "                        samples=64, fixed=True, threshold=None):\n",
    "    if fixed:\n",
    "        noise = torch.randn(samples, 100, 1, 1)\n",
    "    else:\n",
    "        noise = None\n",
    "    for i, path in enumerate(weight_paths):\n",
    "        G = load_generator(path, act, norm)\n",
    "        output_fname = f\"{path.split('/')[-1].strip('.pth')}.png\"\n",
    "        generate_dc_samples(G, output_dir, output_fname, samples, noise, \n",
    "                            threshold)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:28:21.019786Z",
     "start_time": "2019-07-08T01:28:12.086372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded from cat_samples5/5.pth.\n",
      "Output image saved to cat_samples_misc/5.png.\n",
      "\n",
      "Weights loaded from cat_samples5/6.pth.\n",
      "Output image saved to cat_samples_misc/6.png.\n",
      "\n",
      "Weights loaded from cat_samples5/7.pth.\n",
      "Output image saved to cat_samples_misc/7.png.\n",
      "\n",
      "Weights loaded from cat_samples5/8.pth.\n",
      "Output image saved to cat_samples_misc/8.png.\n",
      "\n",
      "Weights loaded from cat_samples5/10.pth.\n",
      "Output image saved to cat_samples_misc/10.png.\n",
      "\n",
      "Weights loaded from cat_samples5/12.pth.\n",
      "Output image saved to cat_samples_misc/12.png.\n",
      "\n",
      "Weights loaded from cat_samples5/13.pth.\n",
      "Output image saved to cat_samples_misc/13.png.\n",
      "\n",
      "Weights loaded from cat_samples5/14.pth.\n",
      "Output image saved to cat_samples_misc/14.png.\n",
      "\n",
      "Weights loaded from cat_samples5/15.pth.\n",
      "Output image saved to cat_samples_misc/15.png.\n",
      "\n",
      "Weights loaded from cat_samples5/31.pth.\n",
      "Output image saved to cat_samples_misc/31.png.\n",
      "\n",
      "Weights loaded from cat_samples5/41.pth.\n",
      "Output image saved to cat_samples_misc/41.png.\n",
      "\n",
      "Weights loaded from cat_samples5/44.pth.\n",
      "Output image saved to cat_samples_misc/44.png.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_model_samples(fnames, output_dir, JRelu, samples=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:10:02.686265Z",
     "start_time": "2019-07-08T01:10:02.683799Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:10:45.089723Z",
     "start_time": "2019-07-08T01:10:44.983775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded from cat_samples5/10.pth.\n"
     ]
    }
   ],
   "source": [
    "G = load_generator(fnames[4], JRelu)\n",
    "noise = torch.randn(2, 100, 1, 1)\n",
    "out = G(noise).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:21:34.765753Z",
     "start_time": "2019-07-08T01:21:34.763145Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:21:37.641905Z",
     "start_time": "2019-07-08T01:21:37.611955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    11320\n",
       "1.0      968\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts((out[0] < -.75).astype(float).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:22:19.137487Z",
     "start_time": "2019-07-08T01:22:19.131518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    11473\n",
       "0.0      815\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(1 - (out[1] < -.95).astype(float).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T01:25:11.476344Z",
     "start_time": "2019-07-08T01:25:11.428207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 108x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(1.5, 1.5))\n",
    "plt.imshow((out[1].mean(0) < -.5).astype(float), \n",
    "           cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
